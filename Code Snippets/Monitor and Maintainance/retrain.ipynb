{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Retrain Periodically\n",
    "Machine learning models can degrade over time due to changes in data patterns, known as data drift or concept drift. Regular retraining helps ensure that models remain accurate and relevant as the underlying data evolves.\n",
    "\n",
    "Triggers for Retraining:\n",
    "- New Data Availability: \n",
    "    - Retrain when sufficient new data accumulates (typically 10-20% of the original training volume).\n",
    "    - Example: A fraud detection model should be retrained when new transaction data becomes available.\n",
    "- Performance Degradation: \n",
    "    - Monitor key performance metrics (e.g., accuracy, precision, recall, F1-score).\n",
    "    - Retrain when metrics fall below predefined thresholds.\n",
    "    - Example: If the accuracy of a recommendation system drops below 90%, trigger retraining.\n",
    "- Detected Drift: \n",
    "    - Use statistical tests (e.g., Kolmogorov-Smirnov, Chi-Square) to detect changes in feature distributions or prediction patterns.\n",
    "- Upstream Data Changes: \n",
    "    - Modifications in data sources, schemas, or preprocessing steps can affect model inputs, necessitating retraining.\n",
    "- Changing Business Requirements: \n",
    "    - Shifts in organizational goals or key performance indicators (KPIs) might require model updates to align with new priorities.\n",
    "\n",
    "Implementation Strategies:\n",
    "- Scheduled Retraining: \n",
    "    - Set up a regular retraining cycle (e.g., daily, weekly, monthly) depending on how rapidly your data changes.\n",
    "- Triggered Retraining: \n",
    "    - Implement automated pipelines that continuously monitor model performance and data distributions.\n",
    "    - Retrain when deviations exceed preset thresholds.\n",
    "    - Example: Use a monitoring system to detect performance degradation and trigger retraining automatically..\n",
    "- Pipeline Integration: \n",
    "    - Integrate retraining into your CI/CD pipelines using tools like Kubeflow, Apache Airflow, or custom automation scripts.\n",
    "    - Automate the entire processâ€”from data extraction and preprocessing to model evaluation and deployment.\n",
    "    - Example: Use Kubeflow to automate the retraining and deployment of a sales forecasting model.\n",
    "\n",
    "\n",
    "#### Best Practices for Retraining\n",
    "\n",
    "1) Version Control:\n",
    "Use tools like DVC or MLflow to track model versions, datasets, and hyperparameters.\n",
    "Example: Track changes in training data and model performance over time.\n",
    "2) Automated Testing:\n",
    "Include automated tests for data quality, model performance, and deployment readiness.\n",
    "Example: Use unit tests to ensure the retrained model meets performance thresholds.\n",
    "3) Rollback Strategies:\n",
    "Implement rollback mechanisms to revert to a previous model version if the retrained model underperforms.\n",
    "Example: Use Kubernetes to roll back to a previous Docker image if the new model fails.\n",
    "4) Monitoring:\n",
    "Continuously monitor model performance and data drift in production.\n",
    "Example: Use Prometheus and Grafana to track accuracy and latency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scheduled Retraining with Apache Airflow\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Define the retraining function\n",
    "def retrain_model():\n",
    "    # Load new data\n",
    "    new_data = pd.read_csv('new_data.csv')\n",
    "    X_new, y_new = new_data.drop('target', axis=1), new_data['target']\n",
    "\n",
    "    # Load the existing model\n",
    "    model = joblib.load('model.pkl')\n",
    "\n",
    "    # Retrain the model\n",
    "    model.fit(X_new, y_new)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_new)\n",
    "    accuracy = accuracy_score(y_new, y_pred)\n",
    "    print(f\"Retrained Model Accuracy: {accuracy}\")\n",
    "\n",
    "    # Save the retrained model\n",
    "    joblib.dump(model, 'model.pkl')\n",
    "\n",
    "# Define the DAG\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'start_date': datetime(2023, 1, 1),\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'retrain_model_dag',\n",
    "    default_args=default_args,\n",
    "    description='A DAG to retrain the model periodically',\n",
    "    schedule_interval=timedelta(days=7),  # Retrain weekly\n",
    ")\n",
    "\n",
    "# Define the task\n",
    "retrain_task = PythonOperator(\n",
    "    task_id='retrain_model',\n",
    "    python_callable=retrain_model,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "retrain_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triggered Retraining with Monitoring\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the existing model\n",
    "model = joblib.load('model.pkl')\n",
    "\n",
    "# Load new data\n",
    "new_data = pd.read_csv('new_data.csv')\n",
    "X_new, y_new = new_data.drop('target', axis=1), new_data['target']\n",
    "\n",
    "# Evaluate the model on new data\n",
    "y_pred = model.predict(X_new)\n",
    "accuracy = accuracy_score(y_new, y_pred)\n",
    "\n",
    "# Check if accuracy falls below a threshold\n",
    "if accuracy < 0.9:  # Threshold = 90%\n",
    "    print(\"Model performance degraded. Retraining...\")\n",
    "    model.fit(X_new, y_new)\n",
    "    joblib.dump(model, 'model.pkl')\n",
    "    print(\"Model retrained and saved.\")\n",
    "else:\n",
    "    print(\"Model performance is acceptable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Integration with Kubeflow\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import func_to_container_op\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# Define the retraining function\n",
    "def retrain_model():\n",
    "    # Load new data\n",
    "    new_data = pd.read_csv('new_data.csv')\n",
    "    X_new, y_new = new_data.drop('target', axis=1), new_data['target']\n",
    "\n",
    "    # Load the existing model\n",
    "    model = joblib.load('model.pkl')\n",
    "\n",
    "    # Retrain the model\n",
    "    model.fit(X_new, y_new)\n",
    "\n",
    "    # Save the retrained model\n",
    "    joblib.dump(model, 'retrained_model.pkl')\n",
    "\n",
    "# Convert the function to a Kubeflow component\n",
    "retrain_op = func_to_container_op(retrain_model)\n",
    "\n",
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "    name='Retrain Pipeline',\n",
    "    description='A pipeline to retrain the model periodically.'\n",
    ")\n",
    "def retrain_pipeline():\n",
    "    retrain_task = retrain_op()\n",
    "\n",
    "# Compile and run the pipeline\n",
    "kfp.compiler.Compiler().compile(retrain_pipeline, 'retrain_pipeline.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
