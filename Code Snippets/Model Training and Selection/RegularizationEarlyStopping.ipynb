{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "Early stopping is used to monitor the validation performance of the model during training, and it halts the training process when the model starts to overfit so it prevent it(i.e., when the validation loss stops improving).Some type of models support early stop natively.\n",
    "\n",
    " Stopping Condition:\n",
    "If the monitored metric does not improve for a specified number of epochs (called patience), training is stopped.The model's weights are restored to the point where the validation performance was best.\n",
    " Min Delta: The minimum change in the monitored metric to qualify as an improvement.\n",
    "For example, if min_delta=0.01, the metric must improve by at least 0.01 to be considered an improvement.\n",
    "\n",
    "\n",
    "* Disadvantages of Early Stopping:\n",
    "\n",
    " Risk of Underfitting:\n",
    " If patience is too low, training may stop before the model has fully learned the data.Choosing inappropriate values for patience or min delta can lead to suboptimal results.\n",
    " The quality of early stopping depends on the representativeness of the validation set.\n",
    "\n",
    "\n",
    "* Best Practices for Early Stopping\n",
    "\n",
    "1) Choose the Right Metric: Use a metric that aligns with your problem (e.g., validation loss for regression, accuracy for classification).\n",
    "2) Set Appropriate Patience:Start with a moderate patience value (e.g., 10-20 epochs) and adjust based on the dataset size and complexity.\n",
    "3) Use a Representative Validation Set:Ensure the validation set is representative of the overall data distribution.\n",
    "4) Combine with Other Regularization Techniques:Use early stopping alongside dropout, weight decay, or data augmentation for better generalization.\n",
    "5) Monitor Training and Validation Curves: Plot training and validation metrics to visually inspect for overfitting and determine the best stopping point.\n",
    "6) You can use early stopping and regularization techniques normally when is a gradient boosting models (XGBoost, LightGBM, CatBoost) or deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example: Load a dataset (replace this with your actual dataset)\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Step 1: Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Convert the data into DMatrix format (required by XGBoost)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Step 3: Define the parameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Binary classification\n",
    "    'eval_metric': 'logloss',        # Metric to monitor (log loss for binary classification)\n",
    "    'max_depth': 6,                  # Maximum depth of a tree\n",
    "    'eta': 0.1,                      # Learning rate\n",
    "    'subsample': 0.8,                # Subsample ratio of the training instances\n",
    "    'colsample_bytree': 0.8,         # Subsample ratio of columns\n",
    "    'reg_alpha': 0.1,  # L1 Regularization\n",
    "    'reg_lambda': 0.5,  # L2 Regularization\n",
    "    'seed': 42                       # Random seed for reproducibility\n",
    "}\n",
    "\n",
    "# Step 4: Train the model with early stopping\n",
    "evals = [(dtrain, 'train'), (dval, 'val')]  # Evaluation sets to monitor\n",
    "num_round = 100  # Maximum number of boosting rounds\n",
    "\n",
    "# Train the model\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_round,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=10,  # Stop if no improvement for 10 rounds on  validation loss (logloss)\n",
    "    verbose_eval=10            # Print evaluation results every 10 rounds\n",
    ")\n",
    "\n",
    "# Step 5: Make predictions on the validation set\n",
    "y_pred = model.predict(dval)\n",
    "y_pred_binary = [1 if p > 0.5 else 0 for p in y_pred]  # Convert probabilities to binary predictions\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred_binary)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load example dataset (Breast Cancer dataset)\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create LightGBM datasets\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'binary',  # Binary classification\n",
    "    'metric': 'binary_logloss',  # Metric to monitor (log loss for binary classification)\n",
    "    'boosting_type': 'gbdt',  # Gradient Boosting Decision Tree\n",
    "    'num_leaves': 31,  # Number of leaves in a tree\n",
    "    'learning_rate': 0.05,  # Learning rate\n",
    "    'feature_fraction': 0.9,  # Fraction of features to use for each tree\n",
    "    'verbose': -1  # Suppress LightGBM logs\n",
    "}\n",
    "\n",
    "# Train the model with early stopping\n",
    "num_round = 1000  # Maximum number of boosting rounds\n",
    "early_stopping_rounds = 50  # Stop if no improvement for 50 rounds\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=num_round,\n",
    "    valid_sets=[val_data],\n",
    "    callbacks=[lgb.early_stopping(early_stopping_rounds)],  # Early stopping callback\n",
    "    verbose_eval=10  # Print evaluation every 10 rounds\n",
    ")\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "y_pred_class = [1 if p > 0.5 else 0 for p in y_pred]  # Convert probabilities to class labels\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred_class)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Best Iteration: {model.best_iteration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization techniques \n",
    "Essential for controlling model complexity and preventing overfitting. \n",
    "\n",
    "They work by adding a penalty term to the loss function, which discourages the model from fitting the noise in the training data. Regularization techniques like L1 (Lasso) and L2 (Ridge) penalize the magnitude of the model's coefficients. If features are on different scales, the penalty term will disproportionately affect larger-scaled features, leading to suboptimal results.To address this, you should standardize or normalize your features during the preprocessing phase.\n",
    "\n",
    "Regularization Strength (alpha):Controls the overall impact of the penalty term. Higher values of alpha increase regularization, reducing overfitting but potentially underfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 Regularization (Lasso)\n",
    "Encourages sparsity by shrinking some coefficients to zero, effectively performing feature selection.\n",
    "Use Case: When you suspect that only a subset of features is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Lasso model\n",
    "lasso = Lasso(alpha=0.1)  # alpha is the regularization strength (lambda)\n",
    "\n",
    "# Train the model\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = lasso.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# View coefficients (some may be zero)\n",
    "print(\"Coefficients:\", lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Regularization (Ridge)\n",
    "Shrinks all coefficients but does not set them to zero, resulting in smaller, non-zero values.\n",
    "Use Case: When all features are potentially relevant, but you want to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Ridge model\n",
    "ridge = Ridge(alpha=1.0)  # alpha is the regularization strength (lambda)\n",
    "\n",
    "# Train the model\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = ridge.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# View coefficients (all are non-zero but smaller)\n",
    "print(\"Coefficients:\", ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ElasticNet Regularization\n",
    "Can set some coefficients to zero (like Lasso) while shrinking others (like Ridge).\n",
    "Use Case: When you want a balance between feature selection and preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize ElasticNet model\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)  # l1_ratio controls the mix of L1 and L2\n",
    "\n",
    "# Train the model\n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = elastic_net.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# View coefficients (some may be zero, others shrunk)\n",
    "print(\"Coefficients:\", elastic_net.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
